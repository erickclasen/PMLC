# Vectors_Linear_Algebra
This is the code for "Vectors - The Math of Intelligence #3" By Siraj Raval on Youtube

# Coding Challenge - Due Date, Thursday July 6 2017 at 12 PM PST

This week's challenge is to use either the L1 or L2 norm to regularize a linear regression model. You can use [this](https://github.com/dgplex/predicting-housing-prices) repositiory as a guide. Use any any dataset you'd like except for 'housing prices'. [Kaggle](https://www.kaggle.com/datasets) is a pretty good place to find datasets. By doing this challenge you'll witness the 3 main ways vectors are used in ML (to represent input data, to represent our model weights, and to regularize our model). Bonus points if your code is well-documented. Good luck!

## Overview

This is the code for [this](https://www.youtube.com/watch?v=s0Q3CojqRfM&feature=youtu.be) video on Youtube by Siraj Raval as part of The Math of Intelligence series. Basically, its just 2 pieces of code that I used to show an example. One compares the dot product operation to standard multiplication to show how linear algebra is faster when we have several numbers to calculate simultaneously. The other is just a simple neural network to show that vectors don't just represent data, they represent our model's learnings.

## Dependencies

* numpy

Install missing dependencies with [pip](https://pip.pypa.io/en/stable/)

## Usage

Run `python name_of_file.py` in terminal and it will run.

## Credits

Credits go to [trask](http://iamtrask.github.io/2015/07/12/basic-python-network/) for the code. I've merely created a wrapper to get people started.
